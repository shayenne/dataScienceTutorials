{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning problems, in general, are concerning in find properties of unknow data from a colection of of $n$ samples of multivariate data.  \n",
    "\n",
    "There are few categories of learning:\n",
    " \n",
    " - supervised learning: the data have an target together of its properties, i.e., features\n",
    "     - classification: the desirable output is one or more classes in a set of possible classes  \n",
    "     - regression: the desirable output is one or more continuous variables\n",
    " - unsupervised learning: set of input vectors without targets\n",
    "     The goal is to find groups of similar examples (clustering), or determine probability distribution (density estimation) or project data from high-dimensional space down to two or three dimensions (visualization)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A commom pratice in machine learning is to learn properties of a group of data and apply it to another group. For this reason, we split the data into train and tes sets.\n",
    "The train set is used to learn some properties and the test set is used to evaluate the learned properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a 2D array, shape (n_samples, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)             # Model to classify data, gamma and C are parameters\n",
    "clf.fit(digits.data[:-1], digits.target[:-1])  # Add data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(digits.data[-1:])                  # Predicting new data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize this image to verify the classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa21f409d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model persistence\n",
    "\n",
    "Since you train your model, you want to save it to use in new data. It is interesting to use joblib to save your models, it is more efficient on big data, saving into the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.joblib') \n",
    "\n",
    "# After you can reload your model\n",
    "clf = joblib.load('filename.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass $\\times$ multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task performed is dependent on the format of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [0, 0, 1, 1, 2]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(gamma='auto',     # 'auto' will be 'scale' in 0.22 version of sklearn\n",
    "                                            random_state=0))\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be binarized for multiclass indicators. Only one class for each feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = LabelBinarizer().fit_transform(y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel instances classification assigns one or more classes for each feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a dataset for classification task is the iris dataset. It is composed by data from 3 different irises (Setosa, Versicolour, and Virginica). The properties of each example are petal and sepal length and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (k-nearest neighbors)\n",
    "\n",
    "Find, for a new observation $X_{test}$, the $k$ closest observations in train set. The $X_{test}$ observation is classified as being of the same class of the majoritary class between de $k$ closest observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split iris data in train and test data\n",
    "# A random permutation, to split the data randomly\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test  = iris_X[indices[-10:]]\n",
    "iris_y_test  = iris_y[indices[-10:]]\n",
    "# Create and fit a nearest-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train) \n",
    "\n",
    "\n",
    "\n",
    "knn.predict(iris_X_test)\n",
    "\n",
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
